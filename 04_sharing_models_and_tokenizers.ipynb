{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_sharing_models_and_tokenizers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzw0UsgcNMzRDSFJl8Glsp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/educatorsRlearners/hugging_face_course/blob/main/04_sharing_models_and_tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using pretrained models\n",
        "\n",
        "The Model Hub makes it incredibly straightforward to selecet a pretrained model based on the task we want to achieve. \n",
        "\n",
        "Why is that important? \n",
        "\n",
        "Becasue, as Alan Maley once said, \n",
        "\n",
        "> The question isn't \"We have this tech; what can we use it for?\" The question is, \"We have this problem. What tech can we use to solve it?\" \n",
        "\n",
        "So, if we want to fill some masks in French, we can import ```camembert-base``` and use it in a pipeline."
      ],
      "metadata": {
        "id": "xB7lQZFcesOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers sentencepiece "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OInOdxWUfbRK",
        "outputId": "4c44677f-eb19-4a58-c252-32a2cb8c0e4d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 25.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import  pipeline\n",
        "\n",
        "checkpoint = 'camembert-base'\n",
        "task = \"fill-mask\"\n",
        "\n",
        "camembert_fill_mask = pipeline(task, checkpoint)\n",
        "\n",
        "result = camembert_fill_mask(\"Le camembert est <mask> :) \")\n",
        "\n",
        "for r in result:\n",
        "  print(round(r['score'], 2), r[\"token_str\"], r['sequence'], sep=\"---\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY2AlA0dfeaY",
        "outputId": "2a8efa7d-ed68-44fa-fc03-b4f9eb4897d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49---délicieux---Le camembert est délicieux :)\n",
            "0.11---excellent---Le camembert est excellent :)\n",
            "0.03---succulent---Le camembert est succulent :)\n",
            "0.03---meilleur---Le camembert est meilleur :)\n",
            "0.03---parfait---Le camembert est parfait :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Easy right? \n",
        "\n",
        "Just be careful to check and see that the checkpoint's head is suitable for the task. For instance, the ```camembert-base``` checkpoint has not been trained for sequence classification tasks. \n",
        "\n",
        "Finally, we can instantiate the checkpoint directly using the either the model architecture:"
      ],
      "metadata": {
        "id": "6lSJxIwcg_KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CamembertTokenizer, CamembertForMaskedLM\n",
        "\n",
        "tokenizer = CamembertTokenizer.from_pretrained(checkpoint)\n",
        "moedl = CamembertForMaskedLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "teTes_6Ff-46"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But, if you want to be more flexible, then use the ```Auto*``` classes like this: "
      ],
      "metadata": {
        "id": "spF5yeOeiQB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import  AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForMaskedLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "ByvqOoxRh7FT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Sharing pretrained models](https://huggingface.co/course/chapter4/3?fw=pt)"
      ],
      "metadata": {
        "id": "WITUyv5VjiYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lAOL8dHtioxO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}